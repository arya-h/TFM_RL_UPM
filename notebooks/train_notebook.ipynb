{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cu102.html\n",
      "Requirement already satisfied: torch in /home/students/s290510/.local/lib/python3.7/site-packages (1.11.0)\n",
      "Requirement already satisfied: torch-scatter in /home/students/s290510/.local/lib/python3.7/site-packages (2.0.9)\n",
      "Requirement already satisfied: torch-sparse in /home/students/s290510/.local/lib/python3.7/site-packages (0.6.13)\n",
      "Requirement already satisfied: torch-cluster in /home/students/s290510/.local/lib/python3.7/site-packages (1.6.0)\n",
      "Requirement already satisfied: torch-spline-conv in /home/students/s290510/.local/lib/python3.7/site-packages (1.2.1)\n",
      "Requirement already satisfied: torch-geometric in /home/students/s290510/.local/lib/python3.7/site-packages (2.0.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from torch-sparse) (1.5.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from torch-geometric) (2.24.0)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from torch-geometric) (2.4.7)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from torch-geometric) (1.19.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from torch-geometric) (4.50.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from torch-geometric) (2.11.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from torch-geometric) (0.23.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from requests->torch-geometric) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from requests->torch-geometric) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from requests->torch-geometric) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from requests->torch-geometric) (2021.5.30)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages (from jinja2->torch-geometric) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cu102.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "import torch\n",
    "\n",
    "import torch_geometric\n",
    "from datetime import datetime\n",
    "from torch_geometric.nn import GAE\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "from actor import PtrNet1\n",
    "from critic import PtrNet2\n",
    "from env import Env_tsp\n",
    "from config import Config, load_pkl, pkl_parser\n",
    "from data import Generator\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(batch_coord):\n",
    "  res_arr = []\n",
    "\n",
    "  #loop through batch to generate batch of embeddings\n",
    "  for coord in batch_coord:\n",
    "\n",
    "    \n",
    "    coord = coord.float()\n",
    "    perm = itertools.permutations(range(10), 2)\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "\n",
    "    for x in perm:\n",
    "        l1.append(x[0])\n",
    "        l2.append(x[1])\n",
    "\n",
    "    a1 = torch.LongTensor(l1)\n",
    "    a2 = torch.LongTensor(l2)\n",
    "\n",
    "    res = [a1,a2]\n",
    "    res = torch.stack(res)\n",
    "\n",
    "    \n",
    "    #feat is x.data\n",
    "    transform = T.Cartesian(cat=False)\n",
    "    data = Data(x=coord, edge_index=torch.LongTensor(res), pos=coord)\n",
    "    data = transform(data) #apply cartesian transform to add edge_attributes as distance between nodes\n",
    "    data = RandomLinkSplit(data)\n",
    "    data = data.num_val\n",
    "    #generate embedding for graph nodes\n",
    "    embedding = model_embed.encode(data.x, data.edge_index, data.edge_attr)\n",
    "    res_arr.append(embedding)\n",
    "  #print(torch.stack([res_arr[0], res_arr[1]], dim=0))\n",
    "\n",
    "  #from list of graph embeddings reshape into batch of embeddings\n",
    "  batch = torch.stack([res_arr[0], res_arr[1]], dim=0)\n",
    "  #print(f\"shape of batch is {batch.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "  return batch\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(cfg, env, log_path = None):\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\t\n",
    "\tdate = datetime.now().strftime('%m%d_%H_%M')\n",
    "\tif cfg.islogger:\n",
    "\t\tparam_path = cfg.log_dir + '%s_%s_param.csv'%(date, cfg.task)# cfg.log_dir = ./Csv/\n",
    "\t\tprint(f'generate {param_path}')\n",
    "\t\twith open(param_path, 'w') as f:\n",
    "\t\t\tf.write(''.join('%s,%s\\n'%item for item in vars(cfg).items()))\n",
    "\n",
    "\t#define actor model\n",
    "\tact_model = PtrNet1(cfg)\n",
    "\t\n",
    "    \n",
    "\tif cfg.optim == 'Adam':\n",
    "\t\tact_optim = optim.Adam(act_model.parameters(), lr = cfg.lr)\n",
    "\tif cfg.is_lr_decay:\n",
    "\t\tact_lr_scheduler = optim.lr_scheduler.StepLR(act_optim, \n",
    "\t\t\t\t\t\tstep_size=cfg.lr_decay_step, gamma=cfg.lr_decay)\n",
    "\tdevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\tact_model = act_model.to(device)\n",
    "\n",
    "\tif cfg.mode == 'train':\n",
    "\t\tcri_model = PtrNet2(cfg)\n",
    "\t\tif cfg.optim == 'Adam':\n",
    "\t\t\tcri_optim = optim.Adam(cri_model.parameters(), lr = cfg.lr)\n",
    "\t\tif cfg.is_lr_decay:\n",
    "\t\t\tcri_lr_scheduler = optim.lr_scheduler.StepLR(cri_optim, \n",
    "\t\t\t\t\t\tstep_size = cfg.lr_decay_step, gamma = cfg.lr_decay)\n",
    "\t\tcri_model = cri_model.to(device)\n",
    "\t\tave_cri_loss = 0.\n",
    "\n",
    "\tmse_loss = nn.MSELoss()\n",
    "\tdataset = Generator(cfg, env)\n",
    "\tdataloader = DataLoader(dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "\tave_act_loss, ave_L = 0., 0.\n",
    "\tmin_L, cnt = 1e7, 0\n",
    "\tt1 = time()\n",
    "\t\n",
    "\n",
    "\t# for i, inputs in tqdm(enumerate(dataloader)):\n",
    "\tfor i, inputs in enumerate(dataloader):\n",
    "\t\t\n",
    "\t\tinputs = inputs.to(device)\n",
    "\t\t#extract first set of nodes from batch to plot a graph for every epoch\n",
    "\t\tcoord = inputs[0]\n",
    "\t\tembedding = generate_embedding(inputs)\n",
    "\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here the actor model is fed with the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\t\n",
    "\t\tpred_tour, ll = act_model(embedding, device)\n",
    "\t\ttour = pred_tour[0]\n",
    "\t\tenv.show(coord, tour)\n",
    "\t\treal_l = env.stack_l_fast(embedding, pred_tour)\n",
    "\t\tif cfg.mode == 'train':\n",
    "\t\t\tpred_l = cri_model(embedding, device)\n",
    "\t\t\tcri_loss = mse_loss(pred_l, real_l.detach())\n",
    "\t\t\tcri_optim.zero_grad()\n",
    "\t\t\tcri_loss.backward(retain_graph=True)\n",
    "\t\t\tnn.utils.clip_grad_norm_(cri_model.parameters(), max_norm = 1., norm_type = 2)\n",
    "\t\t\tcri_optim.step()\n",
    "\t\t\tif cfg.is_lr_decay:\n",
    "\t\t\t\tcri_lr_scheduler.step()\n",
    "\t\telif cfg.mode == 'train_emv':\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tL = real_l.detach().mean()\n",
    "\t\t\telse:\n",
    "\t\t\t\tL = (L * 0.9) + (0.1 * real_l.detach().mean())\n",
    "\t\t\tpred_l = L\n",
    "\n",
    "\t\tadv = real_l.detach() - pred_l.detach()\n",
    "\t\tact_loss = (adv * ll).mean()\n",
    "\t\tact_optim.zero_grad()\n",
    "\t\tact_loss.backward(retain_graph=True)\n",
    "\t\tnn.utils.clip_grad_norm_(act_model.parameters(), max_norm = 1., norm_type = 2)\n",
    "\t\tact_optim.step()\n",
    "\t\tif cfg.is_lr_decay:\n",
    "\t\t\tact_lr_scheduler.step()\n",
    "\n",
    "\t\tave_act_loss += act_loss.item()\n",
    "\t\tif cfg.mode == 'train':\n",
    "\t\t\tave_cri_loss += cri_loss.item()\n",
    "\t\tave_L += real_l.mean().item()\n",
    "\t\t\n",
    "\t\tif i % cfg.log_step == 0:\n",
    "\t\t\tt2 = time()\n",
    "\t\t\tif cfg.mode == 'train':\t\n",
    "\t\t\t\tprint('step:%d/%d, actic loss:%1.3f, critic loss:%1.3f, L:%1.3f, %dmin%dsec'%(i, cfg.steps, ave_act_loss/(i+1), ave_cri_loss/(i+1), ave_L/(i+1), (t2-t1)//60, (t2-t1)%60))\n",
    "\t\t\t\tif cfg.islogger:\n",
    "\t\t\t\t\tif log_path is None:\n",
    "\t\t\t\t\t\tlog_path = cfg.log_dir + '%s_%s_train.csv'%(date, cfg.task)#cfg.log_dir = ./Csv/\n",
    "\t\t\t\t\t\twith open(log_path, 'w') as f:\n",
    "\t\t\t\t\t\t\tf.write('step,actic loss,critic loss,average distance,time\\n')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\twith open(log_path, 'a') as f:\n",
    "\t\t\t\t\t\t\tf.write('%d,%1.4f,%1.4f,%1.4f,%dmin%dsec\\n'%(i, ave_act_loss/(i+1), ave_cri_loss/(i+1), ave_L/(i+1), (t2-t1)//60, (t2-t1)%60))\n",
    "\t\t\t\n",
    "\t\t\tif(ave_L/(i+1) < min_L):\n",
    "\t\t\t\tmin_L = ave_L/(i+1)\t\n",
    "\t\t\telse:\n",
    "\t\t\t\tcnt += 1\n",
    "\t\t\t\tprint(f'cnt: {cnt}/20')\n",
    "\t\t\t\tif(cnt >= 500):\n",
    "\t\t\t\t\tprint('early stop, average cost cant decrease anymore')\n",
    "\t\t\t\t\tif log_path is not None:\n",
    "\t\t\t\t\t\twith open(log_path, 'a') as f:\n",
    "\t\t\t\t\t\t\tf.write('\\nearly stop')\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\tt1 = time()\n",
    "\tif cfg.issaver:\t\t\n",
    "\t\ttorch.save(act_model.state_dict(), cfg.model_dir + '%s_%s_step%d_act.pt'%(cfg.task, date, i))#'cfg.model_dir = ./Pt/'\n",
    "\t\tprint('save model...')\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        \n",
    "from torch_geometric.nn import GAE\n",
    "import itertools\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SplineConv\n",
    "\n",
    "class GraphEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        self.conv1 = SplineConv(in_channels, 2 * out_channels, dim=2, kernel_size=3 ) # cached only for transductive learning\n",
    "        self.conv2 = SplineConv(2 * out_channels, out_channels,dim=2, kernel_size=3) # cached only for transductive learning\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        return self.conv2(x, edge_index, edge_attr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 2\n",
    "out_channels = 16\n",
    "\n",
    "model_embed = GAE(GraphEncoder(2,16))\n",
    "model_embed.load_state_dict(torch.load(\"./models/model_SplineConv_20000.pt\"))\n",
    "\n",
    "model_embed = model_embed.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if __name__ == '__main__':\n",
    "\tcfg = Config()\n",
    "\tenv = Env_tsp(cfg)\n",
    "\n",
    "\ttrain_model(cfg, env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial conclusions as of 27/04\n",
    "- Despite the loss values both for the actor and the critic model going down around 0.3~0.4, and the average length (for the 10 nodes example) going down to 2 (which is a more than optimal value), the tours given by the model are not satisfactory.\n",
    "- I'm afraid that the average length is so low because in the thousands of tours that it performs (from environments generated randomly) , there are some where the distance between points is almost none so it brings the average down to an 'optimal value'.\n",
    "- I'll tweak out the environment to force a certain distance between nodes, otherwise I currently have no other explanation for this behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8c8a949692a8a3908c41fd296327a67f47a79906bfef5e1a234d2cc315ae36e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
