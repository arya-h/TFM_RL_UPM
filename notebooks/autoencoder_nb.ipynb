{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "professional-consideration",
   "metadata": {},
   "source": [
    "## Install torch geometric libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dependent-dynamics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cu102.html\n",
      "Requirement already satisfied: torch in /home/students/s290510/.local/lib/python3.7/site-packages (1.11.0)\n",
      "Requirement already satisfied: torch-scatter in /home/students/s290510/.local/lib/python3.7/site-packages (2.0.9)\n",
      "Requirement already satisfied: torch-sparse in /home/students/s290510/.local/lib/python3.7/site-packages (0.6.13)\n",
      "Requirement already satisfied: torch-cluster in /home/students/s290510/.local/lib/python3.7/site-packages (1.6.0)\n",
      "Requirement already satisfied: torch-spline-conv in /home/students/s290510/.local/lib/python3.7/site-packages (1.2.1)\n",
      "Requirement already satisfied: torch-geometric in /home/students/s290510/.local/lib/python3.7/site-packages (2.0.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from torch-sparse) (1.6.2)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from torch-geometric) (3.0.4)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from torch-geometric) (4.62.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from torch-geometric) (1.21.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from torch-geometric) (2.25.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from torch-geometric) (0.24.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from torch-geometric) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from jinja2->torch-geometric) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from requests->torch-geometric) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from requests->torch-geometric) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from requests->torch-geometric) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from requests->torch-geometric) (2021.10.8)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/bigdatalab_cpu_202201.p37/lib/python3.7/site-packages (from scikit-learn->torch-geometric) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cu102.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suburban-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from env import Env_tsp\n",
    "from config import Config\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handled-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cfg = Config()\n",
    "env = Env_tsp(cfg)\n",
    "#get 20000 node combinations to train the autoencoder on\n",
    "batch_feat =  env.get_batch_nodes(20000)\n",
    "\n",
    "data_list = []\n",
    "for el in batch_feat:\n",
    "    feat = el.double() #array of coordinates\n",
    "    \n",
    "    #to insert information about edge weight (distance between nodes),\n",
    "    #i defined the graph instance as a fully connected one\n",
    "    #data.edge_index: Graph connectivity in COO format with shape [2, num_edges] and type torch.long\n",
    "    #edge index \n",
    "    perm = itertools.permutations(range(5), 2)\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "\n",
    "    for x in perm:\n",
    "        l1.append(x[0])\n",
    "        l2.append(x[1])\n",
    "    \n",
    "    a1 = torch.LongTensor(l1)\n",
    "    a2 = torch.LongTensor(l2)\n",
    "\n",
    "    res = [a1,a2]\n",
    "    res = torch.stack(res)\n",
    "\n",
    "    #add to array of graphs, to save dataset\n",
    "    data = Data(x=feat, edge_index=res, pos=feat )\n",
    "    data_list.append(data)\n",
    "\n",
    "         \n",
    "\n",
    "#save dataset\n",
    "torch.save(data_list, \"./datasets/train_pos_20000.pt\")\n",
    "\n",
    "#loader in case batch norm needed later\n",
    "#loader = DataLoader(data_list, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "macro-answer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/students/s290510/.local/lib/python3.7/site-packages/torch_geometric/data/dataset.py:151: UserWarning: The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you want to make use of another pre-processing technique, make sure to sure to delete 'datasets/processed' first\n",
      "  f\"The `pre_transform` argument differs from the one used in \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root=\"./datasets\", transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data = torch.load(\"./datasets/train_pos_20000.pt\")\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = [...]\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "transform = T.Cartesian(cat=False)\n",
    "dataset = MyOwnDataset(pre_transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "satisfactory-soundtrack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "Data(x=[10, 2], edge_index=[2, 20], pos=[10, 2])\n"
     ]
    }
   ],
   "source": [
    "#verify dataset length\n",
    "print(len(dataset.data))\n",
    "#verify graph structure\n",
    "print((dataset.data)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conscious-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-capital",
   "metadata": {},
   "source": [
    "## Define autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "professional-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "#following torch_geometric autoencoder guide\n",
    "data = dataset.data\n",
    "\n",
    "for _ in range(len(data)):\n",
    "    data[_] = transform(data[_])\n",
    "    data[_].train_mask = data[_].val_mask = data[_].test_mask = None\n",
    "    data[_] = data[_].to(device)\n",
    "    data[_] = RandomLinkSplit(data[_])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21826561",
   "metadata": {},
   "source": [
    "### Graph Encoder module\n",
    "\n",
    "- I contacted the pytorch_geometric team to ask about the optimal layer to use for my use case (fully connected graph whose only features are node coordinates and distance between nodes) and they kindly advised me to use SplineConv <a href=\"https://github.com/pyg-team/pytorch_geometric/discussions/4535\">(here the discussion)</a> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "becoming-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SplineConv\n",
    "\n",
    "class GraphEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        self.conv1 = SplineConv(in_channels, 2 * out_channels, dim=2, kernel_size=3 ) # cached only for transductive learning\n",
    "        self.conv2 = SplineConv(2 * out_channels, out_channels,dim=2, kernel_size=3) # cached only for transductive learning\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        return self.conv2(x, edge_index, edge_attr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "still-arkansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[10, 2], edge_index=[2, 20], pos=[10, 2], edge_attr=[20, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GAE\n",
    "out_channels = 16\n",
    "num_features = 2\n",
    "epochs = 100\n",
    "\n",
    "# model\n",
    "model = GAE(GraphEncoder(num_features, out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.004)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 20000, 0.9999)\n",
    "\n",
    "print(data[0].num_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "loaded-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(cnt):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    obj = data[cnt].num_val\n",
    "    #data[cnt][0].x = (data[cnt][0].x).float().to(device)\n",
    "    obj.x = (obj.x).float().to(device)\n",
    "    obj.edge_attr = (obj.edge_attr).float()\n",
    "    #print(dataset[0][cnt])\n",
    "    z = model.encode(obj.x, obj.edge_index, obj.edge_attr)\n",
    "    loss = model.recon_loss(z,  torch.LongTensor(obj.edge_index))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index, cnt):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data[cnt].x, data[cnt].train_pos_edge_index, data[cnt].train_pos_edge_attr)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead5beb2",
   "metadata": {},
   "source": [
    "Autoencoder in this instance takes 10 nodes with 2 dimensions and outputs a 16-dim embedding of each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "other-colleague",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/students/s290510/.local/lib/python3.7/site-packages/torch_geometric/nn/conv/spline_conv.py:134: UserWarning: We do not recommend using the non-optimized CPU version of `SplineConv`. If possible, please move your data to GPU.\n",
      "  'We do not recommend using the non-optimized CPU version of '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.377434253692627 //epoch : 1\n",
      "loss 1.37760591506958 //epoch : 2\n",
      "loss 1.3952767848968506 //epoch : 3\n",
      "loss 1.3526811599731445 //epoch : 4\n",
      "loss 1.3440523147583008 //epoch : 5\n",
      "loss 1.3370628356933594 //epoch : 6\n",
      "loss 1.3393216133117676 //epoch : 7\n",
      "loss 1.2591071128845215 //epoch : 8\n",
      "loss 1.13352370262146 //epoch : 9\n",
      "loss 1.1536471843719482 //epoch : 10\n",
      "loss 1.0855989456176758 //epoch : 11\n",
      "loss 1.0122826099395752 //epoch : 12\n",
      "loss 1.1327348947525024 //epoch : 13\n",
      "loss 1.1130850315093994 //epoch : 14\n",
      "loss 0.9643628597259521 //epoch : 15\n",
      "loss 1.1634279489517212 //epoch : 16\n",
      "loss 0.8533313274383545 //epoch : 17\n",
      "loss 0.8329411149024963 //epoch : 18\n",
      "loss 0.8164599537849426 //epoch : 19\n",
      "loss 0.7944999933242798 //epoch : 20\n",
      "loss 0.8417636156082153 //epoch : 21\n",
      "loss 0.8002870082855225 //epoch : 22\n",
      "loss 0.6501341462135315 //epoch : 23\n",
      "loss 0.6741078495979309 //epoch : 24\n",
      "loss 0.3577166795730591 //epoch : 25\n",
      "loss 0.4867723286151886 //epoch : 26\n",
      "loss 0.4179753363132477 //epoch : 27\n",
      "loss 0.4104619324207306 //epoch : 28\n",
      "loss 0.4766319990158081 //epoch : 29\n",
      "loss 0.35315561294555664 //epoch : 30\n",
      "loss 0.4410220980644226 //epoch : 31\n",
      "loss 0.32636070251464844 //epoch : 32\n",
      "loss 0.4554803967475891 //epoch : 33\n",
      "loss 0.42542731761932373 //epoch : 34\n",
      "loss 0.4690084755420685 //epoch : 35\n",
      "loss 0.36577871441841125 //epoch : 36\n",
      "loss 0.2640353739261627 //epoch : 37\n",
      "loss 0.3566444516181946 //epoch : 38\n",
      "loss 0.34525540471076965 //epoch : 39\n",
      "loss 0.3238809406757355 //epoch : 40\n",
      "loss 0.28954631090164185 //epoch : 41\n",
      "loss 0.3947826623916626 //epoch : 42\n",
      "loss 0.2892270088195801 //epoch : 43\n",
      "loss 0.36353346705436707 //epoch : 44\n",
      "loss 0.3216345012187958 //epoch : 45\n",
      "loss 0.3452260494232178 //epoch : 46\n",
      "loss 0.27130237221717834 //epoch : 47\n",
      "loss 0.24260511994361877 //epoch : 48\n",
      "loss 0.17291316390037537 //epoch : 49\n",
      "loss 0.2632415294647217 //epoch : 50\n",
      "loss 0.21897174417972565 //epoch : 51\n",
      "loss 0.33619222044944763 //epoch : 52\n",
      "loss 0.3211720585823059 //epoch : 53\n",
      "loss 0.3194599747657776 //epoch : 54\n",
      "loss 0.2920249402523041 //epoch : 55\n",
      "loss 0.3238164782524109 //epoch : 56\n",
      "loss 0.25693508982658386 //epoch : 57\n",
      "loss 0.2966212332248688 //epoch : 58\n",
      "loss 0.20675906538963318 //epoch : 59\n",
      "loss 0.27477583289146423 //epoch : 60\n",
      "loss 0.3304012417793274 //epoch : 61\n",
      "loss 0.19489102065563202 //epoch : 62\n",
      "loss 0.33121898770332336 //epoch : 63\n",
      "loss 0.34431442618370056 //epoch : 64\n",
      "loss 0.20911940932273865 //epoch : 65\n",
      "loss 0.2789710462093353 //epoch : 66\n",
      "loss 0.31323540210723877 //epoch : 67\n",
      "loss 0.34202736616134644 //epoch : 68\n",
      "loss 0.3473452031612396 //epoch : 69\n",
      "loss 0.28613683581352234 //epoch : 70\n",
      "loss 0.28065025806427 //epoch : 71\n",
      "loss 0.34528911113739014 //epoch : 72\n",
      "loss 0.2798331677913666 //epoch : 73\n",
      "loss 0.2412891387939453 //epoch : 74\n",
      "loss 0.18876731395721436 //epoch : 75\n",
      "loss 0.21516017615795135 //epoch : 76\n",
      "loss 0.23849529027938843 //epoch : 77\n",
      "loss 0.14015533030033112 //epoch : 78\n",
      "loss 0.20907121896743774 //epoch : 79\n",
      "loss 0.33159932494163513 //epoch : 80\n",
      "loss 0.3332173824310303 //epoch : 81\n",
      "loss 0.32596564292907715 //epoch : 82\n",
      "loss 0.1743316799402237 //epoch : 83\n",
      "loss 0.23867560923099518 //epoch : 84\n",
      "loss 0.2666989862918854 //epoch : 85\n",
      "loss 0.3387710154056549 //epoch : 86\n",
      "loss 0.18870015442371368 //epoch : 87\n",
      "loss 0.15767593681812286 //epoch : 88\n",
      "loss 0.2598482072353363 //epoch : 89\n",
      "loss 0.2642359435558319 //epoch : 90\n",
      "loss 0.2900056540966034 //epoch : 91\n",
      "loss 0.2635895013809204 //epoch : 92\n",
      "loss 0.21278245747089386 //epoch : 93\n",
      "loss 0.2454301416873932 //epoch : 94\n",
      "loss 0.16082587838172913 //epoch : 95\n",
      "loss 0.19144131243228912 //epoch : 96\n",
      "loss 0.23733603954315186 //epoch : 97\n",
      "loss 0.27310559153556824 //epoch : 98\n",
      "loss 0.2781819999217987 //epoch : 99\n",
      "loss 0.2353105992078781 //epoch : 100\n",
      "loss 0.1915905922651291 //epoch : 101\n",
      "loss 0.15932705998420715 //epoch : 102\n",
      "loss 0.30163857340812683 //epoch : 103\n",
      "loss 0.17217621207237244 //epoch : 104\n",
      "loss 0.19810791313648224 //epoch : 105\n",
      "loss 0.182608962059021 //epoch : 106\n",
      "loss 0.1408175528049469 //epoch : 107\n",
      "loss 0.2000740021467209 //epoch : 108\n",
      "loss 0.23814430832862854 //epoch : 109\n",
      "loss 0.29983019828796387 //epoch : 110\n",
      "loss 0.2714785933494568 //epoch : 111\n",
      "loss 0.2745518684387207 //epoch : 112\n",
      "loss 0.15421798825263977 //epoch : 113\n",
      "loss 0.2529835104942322 //epoch : 114\n",
      "loss 0.28305938839912415 //epoch : 115\n",
      "loss 0.18709924817085266 //epoch : 116\n",
      "loss 0.21926149725914001 //epoch : 117\n",
      "loss 0.3097468614578247 //epoch : 118\n",
      "loss 0.25516369938850403 //epoch : 119\n",
      "loss 0.29822543263435364 //epoch : 120\n",
      "loss 0.2324868142604828 //epoch : 121\n",
      "loss 0.17242872714996338 //epoch : 122\n",
      "loss 0.2297181487083435 //epoch : 123\n",
      "loss 0.10342009365558624 //epoch : 124\n",
      "loss 0.30975937843322754 //epoch : 125\n",
      "loss 0.28684231638908386 //epoch : 126\n",
      "loss 0.17509284615516663 //epoch : 127\n",
      "loss 0.31582707166671753 //epoch : 128\n",
      "loss 0.13117823004722595 //epoch : 129\n",
      "loss 0.16290855407714844 //epoch : 130\n",
      "loss 0.25216469168663025 //epoch : 131\n",
      "loss 0.28255903720855713 //epoch : 132\n",
      "loss 0.319306343793869 //epoch : 133\n",
      "loss 0.17331817746162415 //epoch : 134\n",
      "loss 0.18925714492797852 //epoch : 135\n",
      "loss 0.18738268315792084 //epoch : 136\n",
      "loss 0.2937592566013336 //epoch : 137\n",
      "loss 0.2515685558319092 //epoch : 138\n",
      "loss 0.2448178082704544 //epoch : 139\n",
      "loss 0.3026011884212494 //epoch : 140\n",
      "loss 0.21827928721904755 //epoch : 141\n",
      "loss 0.2056463658809662 //epoch : 142\n",
      "loss 0.2710018754005432 //epoch : 143\n",
      "loss 0.24667540192604065 //epoch : 144\n",
      "loss 0.18992780148983002 //epoch : 145\n",
      "loss 0.13518084585666656 //epoch : 146\n",
      "loss 0.22584781050682068 //epoch : 147\n",
      "loss 0.22148798406124115 //epoch : 148\n",
      "loss 0.1618015170097351 //epoch : 149\n",
      "loss 0.19052830338478088 //epoch : 150\n",
      "loss 0.2510409951210022 //epoch : 151\n",
      "loss 0.16496561467647552 //epoch : 152\n",
      "loss 0.24827662110328674 //epoch : 153\n",
      "loss 0.18431173264980316 //epoch : 154\n",
      "loss 0.18915246427059174 //epoch : 155\n",
      "loss 0.14721223711967468 //epoch : 156\n",
      "loss 0.18702594935894012 //epoch : 157\n",
      "loss 0.16072499752044678 //epoch : 158\n",
      "loss 0.24885888397693634 //epoch : 159\n",
      "loss 0.29412779211997986 //epoch : 160\n",
      "loss 0.247563898563385 //epoch : 161\n",
      "loss 0.3080161213874817 //epoch : 162\n",
      "loss 0.2233973890542984 //epoch : 163\n",
      "loss 0.3584636449813843 //epoch : 164\n",
      "loss 0.18192772567272186 //epoch : 165\n",
      "loss 0.15796241164207458 //epoch : 166\n",
      "loss 0.3017270565032959 //epoch : 167\n",
      "loss 0.2675970196723938 //epoch : 168\n",
      "loss 0.18981952965259552 //epoch : 169\n",
      "loss 0.1922977864742279 //epoch : 170\n",
      "loss 0.19850769639015198 //epoch : 171\n",
      "loss 0.25409600138664246 //epoch : 172\n",
      "loss 0.2995166480541229 //epoch : 173\n",
      "loss 0.29717448353767395 //epoch : 174\n",
      "loss 0.21092304587364197 //epoch : 175\n",
      "loss 0.18241065740585327 //epoch : 176\n",
      "loss 0.28879979252815247 //epoch : 177\n",
      "loss 0.2923993766307831 //epoch : 178\n",
      "loss 0.290326863527298 //epoch : 179\n",
      "loss 0.27720606327056885 //epoch : 180\n",
      "loss 0.1986180543899536 //epoch : 181\n",
      "loss 0.18171526491641998 //epoch : 182\n",
      "loss 0.18007153272628784 //epoch : 183\n",
      "loss 0.18313995003700256 //epoch : 184\n",
      "loss 0.18680988252162933 //epoch : 185\n",
      "loss 0.3706181049346924 //epoch : 186\n",
      "loss 0.15086786448955536 //epoch : 187\n",
      "loss 0.2743869125843048 //epoch : 188\n",
      "loss 0.1306685209274292 //epoch : 189\n",
      "loss 0.23380829393863678 //epoch : 190\n",
      "loss 0.2077249139547348 //epoch : 191\n",
      "loss 0.1745986044406891 //epoch : 192\n",
      "loss 0.1216508224606514 //epoch : 193\n",
      "loss 0.23522105813026428 //epoch : 194\n",
      "loss 0.23362749814987183 //epoch : 195\n",
      "loss 0.27218368649482727 //epoch : 196\n",
      "loss 0.26805901527404785 //epoch : 197\n",
      "loss 0.20388786494731903 //epoch : 198\n",
      "loss 0.17572574317455292 //epoch : 199\n",
      "loss 0.08905491232872009 //epoch : 200\n"
     ]
    }
   ],
   "source": [
    "epoch=1\n",
    "\n",
    "while epoch < 20000:\n",
    "    \n",
    "    loss = train(epoch)\n",
    "    print(f\"loss {loss} //epoch : {epoch}\")\n",
    "    \n",
    "    if loss < 0.1:\n",
    "        torch.save(model.state_dict(), \"./models/model_SplineConv_20000.pt\")\n",
    "        epoch=200000\n",
    "\n",
    "    epoch+=1\n",
    "    \n",
    "torch.save(model.state_dict(), \"./models/third_model_SplineConv_20000.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-color",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7576, 0.2793],\n",
      "        [0.4031, 0.7347],\n",
      "        [0.0293, 0.7999],\n",
      "        [0.3971, 0.7544],\n",
      "        [0.5695, 0.4388],\n",
      "        [0.6387, 0.5247],\n",
      "        [0.6826, 0.3051],\n",
      "        [0.4635, 0.4550],\n",
      "        [0.5725, 0.4980],\n",
      "        [0.9371, 0.6556]], dtype=torch.float64)\n",
      "tensor([[-1.9853e+01, -3.4666e+01, -1.4277e+01, -1.8772e+01, -2.4773e+01,\n",
      "          2.9172e+01,  2.8252e+01,  2.0750e+01,  2.5156e+01, -2.0352e+01,\n",
      "          1.5138e+01, -8.6671e+00,  2.3499e+01,  2.7759e+01,  1.4722e+01,\n",
      "         -3.1795e+01],\n",
      "        [-1.9904e+01, -3.4736e+01, -1.4322e+01, -1.9078e+01, -2.4218e+01,\n",
      "          2.9297e+01,  2.8982e+01,  2.0300e+01,  2.3721e+01, -1.9743e+01,\n",
      "          1.5421e+01, -8.5059e+00,  2.3534e+01,  2.8493e+01,  1.4687e+01,\n",
      "         -3.2552e+01],\n",
      "        [-1.8990e+01, -3.3741e+01, -1.3973e+01, -1.7311e+01, -2.2639e+01,\n",
      "          2.7276e+01,  2.6998e+01,  1.8430e+01,  2.2091e+01, -1.7889e+01,\n",
      "          1.4890e+01, -8.6177e+00,  2.1825e+01,  2.7288e+01,  1.3111e+01,\n",
      "         -3.1782e+01],\n",
      "        [-1.9886e+01, -3.4694e+01, -1.4308e+01, -1.9048e+01, -2.4196e+01,\n",
      "          2.9261e+01,  2.8963e+01,  2.0255e+01,  2.3653e+01, -1.9693e+01,\n",
      "          1.5399e+01, -8.4852e+00,  2.3516e+01,  2.8472e+01,  1.4649e+01,\n",
      "         -3.2525e+01],\n",
      "        [-2.0136e+01, -3.4941e+01, -1.4380e+01, -1.9299e+01, -2.4549e+01,\n",
      "          2.9676e+01,  2.9050e+01,  2.0767e+01,  2.4627e+01, -2.0350e+01,\n",
      "          1.5485e+01, -8.6559e+00,  2.3795e+01,  2.8499e+01,  1.4990e+01,\n",
      "         -3.2499e+01],\n",
      "        [ 2.3116e-02,  3.5167e-02,  2.7450e-02,  3.4772e-02,  2.9082e-02,\n",
      "         -3.3557e-02, -1.5219e-02, -1.4079e-02, -4.4282e-03,  2.0479e-02,\n",
      "          1.3598e-03,  9.4025e-03, -1.8540e-02, -3.9822e-02, -1.4625e-05,\n",
      "          3.7097e-02],\n",
      "        [ 5.7869e-02,  4.1449e-02,  4.5930e-02,  2.5560e-02,  1.4484e-02,\n",
      "         -2.8273e-02, -2.3877e-02, -1.3928e-02,  2.6408e-02,  4.1138e-02,\n",
      "         -2.3689e-02,  5.3889e-02,  9.6347e-04, -3.5283e-02,  3.9560e-02,\n",
      "          2.5784e-02],\n",
      "        [ 1.9050e-02,  2.6933e-02,  9.1797e-03,  1.6832e-02,  2.1881e-02,\n",
      "         -1.9694e-02, -3.3056e-02, -2.0309e-02, -3.2086e-02,  2.5557e-02,\n",
      "         -2.2830e-02, -2.1901e-03, -3.3338e-02, -2.0818e-02, -2.8769e-02,\n",
      "          2.6157e-02],\n",
      "        [ 2.1625e-02,  3.2060e-02,  2.0562e-02,  2.7971e-02,  2.6337e-02,\n",
      "         -2.8304e-02, -2.1980e-02, -1.6436e-02, -1.4852e-02,  2.2428e-02,\n",
      "         -7.8272e-03,  5.0764e-03, -2.4113e-02, -3.2625e-02, -1.0841e-02,\n",
      "          3.2943e-02],\n",
      "        [ 2.8306e-02,  4.8980e-02,  5.7864e-02,  6.6044e-02,  4.2197e-02,\n",
      "         -5.7628e-02,  1.5849e-02, -3.3923e-03,  4.1465e-02,  1.0697e-02,\n",
      "          4.4178e-02,  2.7013e-02,  5.8599e-03, -7.2682e-02,  4.7312e-02,\n",
      "          5.6462e-02]], grad_fn=<AddBackward0>)\n",
      "tensor([[0.3138, 0.1980],\n",
      "        [0.4162, 0.2843],\n",
      "        [0.3398, 0.5239],\n",
      "        [0.7981, 0.7718],\n",
      "        [0.0112, 0.8100],\n",
      "        [0.6397, 0.9743],\n",
      "        [0.8300, 0.0444],\n",
      "        [0.0246, 0.2588],\n",
      "        [0.9391, 0.4167],\n",
      "        [0.7140, 0.2676]])\n",
      "tensor([[-1.7026e+01, -2.8964e+01, -1.1896e+01, -1.6465e+01, -2.0122e+01,\n",
      "          2.5172e+01,  2.4892e+01,  1.7329e+01,  2.0306e+01, -1.7142e+01,\n",
      "          1.3040e+01, -7.1900e+00,  2.0106e+01,  2.4360e+01,  1.2624e+01,\n",
      "         -2.7460e+01],\n",
      "        [-1.6924e+01, -2.9106e+01, -1.1959e+01, -1.6384e+01, -2.0368e+01,\n",
      "          2.5056e+01,  2.4660e+01,  1.7439e+01,  2.0474e+01, -1.7148e+01,\n",
      "          1.2982e+01, -7.1768e+00,  2.0047e+01,  2.4155e+01,  1.2665e+01,\n",
      "         -2.7348e+01],\n",
      "        [-1.6956e+01, -2.9173e+01, -1.2022e+01, -1.6361e+01, -2.0388e+01,\n",
      "          2.4996e+01,  2.4801e+01,  1.7299e+01,  2.0131e+01, -1.6924e+01,\n",
      "          1.3011e+01, -7.1128e+00,  2.0017e+01,  2.4242e+01,  1.2572e+01,\n",
      "         -2.7436e+01],\n",
      "        [-1.6345e+01, -2.7912e+01, -1.1386e+01, -1.5888e+01, -1.9978e+01,\n",
      "          2.3985e+01,  2.3068e+01,  1.6907e+01,  1.9467e+01, -1.6477e+01,\n",
      "          1.1693e+01, -6.1503e+00,  1.9728e+01,  2.2027e+01,  1.2328e+01,\n",
      "         -2.4933e+01],\n",
      "        [-1.6420e+01, -2.8411e+01, -1.1803e+01, -1.5151e+01, -1.9398e+01,\n",
      "          2.3647e+01,  2.3610e+01,  1.5854e+01,  1.8664e+01, -1.5463e+01,\n",
      "          1.2579e+01, -7.0771e+00,  1.8973e+01,  2.3512e+01,  1.1336e+01,\n",
      "         -2.6951e+01],\n",
      "        [-4.2159e-02,  2.3434e-02, -3.4990e-03,  5.7896e-02,  5.4273e-02,\n",
      "         -4.7628e-02,  1.3567e-02, -9.4393e-03, -4.9962e-02, -2.5622e-02,\n",
      "          5.9413e-02, -6.9970e-02, -4.7865e-02, -5.2663e-02, -5.8800e-02,\n",
      "          6.4312e-02],\n",
      "        [ 1.1024e-01,  5.9400e-02,  7.3911e-02, -5.1160e-03,  6.2768e-03,\n",
      "         -4.7412e-02, -6.7068e-02, -1.0618e-02,  5.9156e-02,  7.7836e-02,\n",
      "         -5.7384e-02,  1.2495e-01,  1.3623e-02, -4.0258e-02,  1.0505e-01,\n",
      "          2.7329e-02],\n",
      "        [ 1.0093e-02,  3.2278e-02, -3.3738e-02, -2.5145e-02, -3.3837e-03,\n",
      "         -1.4746e-02, -6.5230e-02, -3.7925e-02, -8.8557e-02,  2.1203e-02,\n",
      "         -9.2770e-02, -7.9909e-04, -4.3424e-02,  1.1727e-02, -7.6346e-02,\n",
      "          8.9353e-03],\n",
      "        [ 6.2464e-02,  5.3337e-02,  7.2123e-02,  5.2379e-02,  2.5688e-02,\n",
      "         -4.8924e-02,  2.7699e-03, -4.7494e-03,  6.5943e-02,  3.2820e-02,\n",
      "          1.2984e-02,  6.9190e-02,  2.1996e-02, -6.3485e-02,  8.0362e-02,\n",
      "          4.2369e-02],\n",
      "        [ 6.5965e-02,  4.3472e-02,  5.2274e-02,  2.4271e-02,  1.2980e-02,\n",
      "         -3.0044e-02, -2.5681e-02, -1.3405e-02,  3.4989e-02,  4.5404e-02,\n",
      "         -2.5903e-02,  6.5297e-02,  6.2062e-03, -3.7325e-02,  5.1717e-02,\n",
      "          2.5527e-02]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/students/s290510/.local/lib/python3.7/site-packages/torch_geometric/nn/conv/spline_conv.py:134: UserWarning: We do not recommend using the non-optimized CPU version of `SplineConv`. If possible, please move your data to GPU.\n",
      "  'We do not recommend using the non-optimized CPU version of '\n"
     ]
    }
   ],
   "source": [
    "obj1 = data[0].num_val\n",
    "obj2 = data[1].num_val\n",
    "\n",
    "Z = model.encode(obj1.x.float(), obj1.edge_index, (obj1.edge_attr).float())\n",
    "Y = model.encode(obj2.x.float(), obj2.edge_index, (obj2.edge_attr).float())\n",
    "print(obj1.x)\n",
    "print(Z)\n",
    "print(obj2.x)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-profession",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
